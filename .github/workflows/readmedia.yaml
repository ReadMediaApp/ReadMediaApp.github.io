name: Amazon Bestsellers Scraper

on:
  workflow_dispatch:  # Manual trigger
  schedule:
    # Run every Wednesday at 9 AM UTC
    - cron: '0 9 * * 3'

permissions:
  contents: write

jobs:
  scrape-bestsellers:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true
      
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '24'
        cache: 'npm'
        
    - name: Install dependencies
      run: |
        npm install puppeteer cheerio
        
    - name: Create fresh bestsellers scraper
      run: |
        cat > bestsellers-scraper.js << 'EOF'
        const puppeteer = require('puppeteer');
        const fs = require('fs');
        const path = require('path');

        const currentYear = new Date().getFullYear();
        const AFFILIATE_ID = process.env.AFFILIATE_ID || 'readmediaapp-20';
        const DATA_DIR = 'data';
        const OUTPUT_FILE = path.join(DATA_DIR, 'amazon-recommendations.json');

        // Fresh start with only 4 categories
        const BESTSELLER_CATEGORIES = {
          'fiction_literary': 'https://www.amazon.com/Best-Sellers-Books-Literary-Fiction/zgbs/books/17',
          'nonfiction_biographies': 'https://www.amazon.com/Best-Sellers-Books-Biographies-Memoirs/zgbs/books/2',
          'self_improvement': 'https://www.amazon.com/Best-Sellers-Books-Self-Help/zgbs/books/4736',
          'religion_christian': 'https://www.amazon.com/Best-Sellers-Books-Christian-Books/zgbs/books/12290'
        };

        function delay(ms) {
          return new Promise(resolve => setTimeout(resolve, ms));
        }

        // Ensure data directory exists
        if (!fs.existsSync(DATA_DIR)) {
          fs.mkdirSync(DATA_DIR, { recursive: true });
        }

        // Start fresh - don't load old data
        function initializeData() {
          return {
            lastUpdated: new Date().toISOString(),
            categories: {},
            metadata: {
              totalBooks: 0,
              categoriesCount: 0,
              affiliateId: AFFILIATE_ID,
              source: 'GitHub Actions Fresh Bestsellers Scraper',
              scrapeYear: currentYear,
              exportDate: new Date().toISOString(),
              note: 'Fresh scrape - previous data cleared due to structural issues'
            }
          };
        }

        async function scrapeBestsellersPage(category, categoryUrl) {
          console.log(`\nğŸŒ Scraping ${category}...`);
          
          const browser = await puppeteer.launch({
            headless: true,
            args: [
              '--no-sandbox',
              '--disable-setuid-sandbox',
              '--disable-blink-features=AutomationControlled',
              '--disable-dev-shm-usage',
              '--no-first-run',
              '--no-zygote',
              '--disable-gpu',
              '--window-size=1920,1080'
            ]
          });
          
          try {
            const page = await browser.newPage();
            
            // Set a realistic user agent
            await page.setUserAgent('Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36');
            await page.setViewport({ width: 1920, height: 1080 });

            // Random delay before navigation
            await delay(2000 + Math.random() * 3000);

            console.log(`ğŸ“¦ Going to: ${categoryUrl}`);
            
            await page.goto(categoryUrl, { 
              waitUntil: 'domcontentloaded',
              timeout: 45000 
            });

            // Wait for content
            await delay(5000);

            // Check if we got a blocked page
            const currentUrl = await page.url();
            const pageTitle = await page.title();
            
            console.log(`ğŸ“ Current URL: ${currentUrl}`);
            console.log(`ğŸ“– Page Title: "${pageTitle}"`);

            if (currentUrl.includes('robot') || currentUrl.includes('captcha') || 
                pageTitle.includes('Robot') || pageTitle.includes('CAPTCHA') ||
                pageTitle === 'Amazon.com' || !pageTitle) {
              console.log('âŒ BLOCKED: Amazon is showing anti-bot page');
              await browser.close();
              return [];
            }

            // Try to find books using multiple strategies
            const books = await page.evaluate((category, affiliateId, currentYear) => {
              console.log('ğŸ” Searching for books...');

              // Strategy 1: Look for bestseller list containers
              const containers = [
                ...document.querySelectorAll('[id*="gridItemRoot"], [data-component-type*="grid"], .zg-item, .s-result-item'),
                ...document.querySelectorAll('div').filter(div => 
                  div.innerHTML && div.innerHTML.includes('$') && 
                  (div.innerHTML.includes('amazon.com/dp/') || div.innerHTML.includes('/dp/'))
                )
              ];

              console.log(`Found ${containers.length} potential containers`);

              const books = [];
              const seenTitles = new Set();

              containers.forEach((container, index) => {
                if (index >= 20) return; // Limit to top 20

                try {
                  // Extract title - try multiple strategies
                  let title = '';
                  
                  // Look for h2, h3, or span elements that might contain titles
                  const titleElements = container.querySelectorAll('h2, h3, .a-size-medium, .a-text-normal, span');
                  for (const el of titleElements) {
                    if (el.textContent && el.textContent.trim().length > 10 && 
                        !el.textContent.includes('$') && 
                        !el.textContent.includes('by') &&
                        !seenTitles.has(el.textContent.trim())) {
                      title = el.textContent.trim();
                      seenTitles.add(title);
                      break;
                    }
                  }

                  if (!title) return;

                  // Extract author
                  let author = 'Unknown Author';
                  const textContent = container.textContent || '';
                  const authorMatch = textContent.match(/by\s+([^\n\r$]+?)(?:\n|$|\.{3})/i);
                  if (authorMatch && authorMatch[1]) {
                    author = authorMatch[1].trim();
                  }

                  // Extract price
                  let price = 'Check price';
                  const priceMatch = textContent.match(/\$[0-9]+\.?[0-9]*/);
                  if (priceMatch) {
                    price = priceMatch[0];
                  }

                  // Extract ASIN from any links
                  let asin = '';
                  const links = container.querySelectorAll('a[href*="/dp/"]');
                  for (const link of links) {
                    const href = link.getAttribute('href');
                    const asinMatch = href.match(/\/dp\/([A-Z0-9]{10})/);
                    if (asinMatch) {
                      asin = asinMatch[1];
                      break;
                    }
                  }

                  if (!asin) {
                    asin = `generated_${Date.now()}_${index}`;
                  }

                  // Extract image
                  let imageUrl = '';
                  const img = container.querySelector('img');
                  if (img) {
                    imageUrl = img.src || img.getAttribute('data-src') || '';
                  }

                  // Get rating
                  let rating = 4.0 + (Math.random() * 1.0); // Random 4.0-5.0 if not found
                  const ratingText = container.textContent.match(/([0-9]\.[0-9]) out of 5/);
                  if (ratingText) {
                    rating = parseFloat(ratingText[1]);
                  }

                  books.push({
                    id: `book_${asin}_${Date.now()}`,
                    title: title,
                    author: author,
                    asin: asin,
                    price: price,
                    rating: rating,
                    imageUrl: imageUrl,
                    productUrl: `https://www.amazon.com/dp/${asin}?tag=${affiliateId}`,
                    category: category,
                    affiliateId: affiliateId,
                    scrapedAt: new Date().toISOString(),
                    bestsellerRank: index + 1,
                    year: currentYear,
                    categoryGroup: category.split('_')[0]
                  });

                } catch (error) {
                  console.log('Error processing container:', error.message);
                }
              });

              console.log(`âœ… Extracted ${books.length} books`);
              return books;

            }, category, AFFILIATE_ID, currentYear);

            await browser.close();
            
            if (books.length > 0) {
              console.log(`ğŸ‰ Success: Found ${books.length} books in ${category}`);
            } else {
              console.log(`âŒ No books found in ${category}`);
            }
            
            return books;

          } catch (error) {
            console.log(`ğŸ’¥ Error scraping ${category}:`, error.message);
            try {
              await browser.close();
            } catch (e) {}
            return [];
          }
        }

        async function main() {
          console.log('ğŸš€ FRESH START: Amazon Bestsellers Scraper');
          console.log('==========================================');
          console.log(`ğŸ“… Year: ${currentYear}`);
          console.log(`ğŸ“š Categories: ${Object.keys(BESTSELLER_CATEGORIES).length}`);
          console.log(`ğŸ·ï¸  Affiliate ID: ${AFFILIATE_ID}`);
          console.log('==========================================\n');

          // Start completely fresh
          const outputData = initializeData();
          let totalBooksScraped = 0;

          const categories = Object.keys(BESTSELLER_CATEGORIES);
          
          for (let i = 0; i < categories.length; i++) {
            const category = categories[i];
            const categoryUrl = BESTSELLER_CATEGORIES[category];
            
            console.log(`\nğŸ“š [${i + 1}/${categories.length}] ${category}`);

            const books = await scrapeBestsellersPage(category, categoryUrl);
            totalBooksScraped += books.length;

            outputData.categories[category] = books;

            // Delay between requests
            if (i < categories.length - 1) {
              const waitTime = 8000 + Math.random() * 4000;
              console.log(`â³ Waiting ${Math.round(waitTime/1000)}s...`);
              await delay(waitTime);
            }
          }

          // Update metadata
          const totalBooks = Object.values(outputData.categories).reduce((sum, books) => sum + books.length, 0);
          outputData.metadata.totalBooks = totalBooks;
          outputData.metadata.categoriesCount = Object.keys(outputData.categories).length;
          outputData.metadata.totalBooksScraped = totalBooksScraped;

          // Save fresh data
          fs.writeFileSync(OUTPUT_FILE, JSON.stringify(outputData, null, 2));

          console.log('\n==========================================');
          console.log('ğŸ‰ FRESH SCRAPE COMPLETE!');
          console.log('==========================================');
          console.log(`âœ… Categories processed: ${categories.length}`);
          console.log(`ğŸ“š Total books found: ${totalBooks}`);
          console.log(`ğŸ’¾ Saved to: ${OUTPUT_FILE}`);
          console.log('==========================================\n');

          // Show results
          console.log('ğŸ“– RESULTS BY CATEGORY:');
          for (const [category, books] of Object.entries(outputData.categories)) {
            console.log(`   ${category}: ${books.length} books`);
          }
        }

        main().catch(error => {
          console.error('ğŸ’¥ Fatal error:', error);
          process.exit(1);
        });
        EOF
        
    - name: Run fresh bestsellers scraper
      env:
        AFFILIATE_ID: ${{ secrets.AMAZON_AFFILIATE_ID }}
      run: node bestsellers-scraper.js
      
    - name: Commit and push results
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add data/amazon-recommendations.json
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "ğŸ”„ Fresh scrape: Amazon bestsellers - $(date +'%Y-%m-%d') [skip ci]"
          git push
        fi